lines(abs(quantile(ab,seq(0.01,1,0.01))-quantile(ab2,seq(0.01,1,0.01))),type='l')
zx=sapply(1:length(ab2),function(x)sum(abs(quantile(ab,seq(0.01,1,0.01))-
quantile(ab2[-x],seq(0.01,1,0.01)))))
ab2=ab2[-order(zx)[1:20]]
lines(abs(quantile(ab,seq(0.01,1,0.01))-quantile(ab2,seq(0.01,1,0.01))),type='l')
zx=sapply(1:length(ab2),function(x)sum(abs(quantile(ab,seq(0.01,1,0.01))-
quantile(ab2[-x],seq(0.01,1,0.01)))))
ab2=ab2[-order(zx)[1:20]]
lines(abs(quantile(ab,seq(0.01,1,0.01))-quantile(ab2,seq(0.01,1,0.01))),type='l')
zx=sapply(1:length(ab2),function(x)sum(abs(quantile(ab,seq(0.01,1,0.01))-
quantile(ab2[-x],seq(0.01,1,0.01)))))
ab2=ab2[-order(zx)[1:20]]
lines(abs(quantile(ab,seq(0.01,1,0.01))-quantile(ab2,seq(0.01,1,0.01))),type='l')
zx=sapply(1:length(ab2),function(x)sum(abs(quantile(ab,seq(0.01,1,0.01))-
quantile(ab2[-x],seq(0.01,1,0.01)))))
ab2=ab2[-order(zx)[1:20]]
lines(abs(quantile(ab,seq(0.01,1,0.01))-quantile(ab2,seq(0.01,1,0.01))),type='l')
zx=sapply(1:length(ab2),function(x)sum(abs(quantile(ab,seq(0.01,1,0.01))-
quantile(ab2[-x],seq(0.01,1,0.01)))))
ab2=ab2[-order(zx)[1:20]]
lines(abs(quantile(ab,seq(0.01,1,0.01))-quantile(ab2,seq(0.01,1,0.01))),type='l')
zx=sapply(1:length(ab2),function(x)sum(abs(quantile(ab,seq(0.01,1,0.01))-
quantile(ab2[-x],seq(0.01,1,0.01)))))
ab2=ab2[-order(zx)[1:20]]
lines(abs(quantile(ab,seq(0.01,1,0.01))-quantile(ab2,seq(0.01,1,0.01))),type='l')
zx=sapply(1:length(ab2),function(x)sum(abs(quantile(ab,seq(0.01,1,0.01))-
quantile(ab2[-x],seq(0.01,1,0.01)))))
ab2=ab2[-order(zx)[1:20]]
lines(abs(quantile(ab,seq(0.01,1,0.01))-quantile(ab2,seq(0.01,1,0.01))),type='l')
plot(density(ab))
lines(density(ab2),col='red')
set.seed(1);ab=rnorm(1000,1,1)
set.seed(1);ab2=rnorm(1000,0.5,1.1)
plot(density(ab))
lines(density(ab2),col='red')
set.seed(1);ab=rnorm(1000,1,1)
set.seed(1);ab2=rnorm(1000,0.5,1.1)
step=0
# plot(abs(quantile(ab,seq(0.01,1,0.01))-quantile(ab2,seq(0.01,1,0.01))),type='l')
while(step<10) {
zx=sapply(1:length(ab2),function(x)sum(abs(quantile(ab,seq(0.01,1,0.01))-
quantile(ab2[-x],seq(0.01,1,0.01)))))
ab2=ab2[-order(zx)[1:20]]
step=step+1
}
wilcox.test(ab2,ab)
set.seed(1);ab=rnorm(1000,1,1)
set.seed(1);ab2=rnorm(1000,1,1.1)
wilcox.test(ab2,ab)
set.seed(1);ab=rnorm(1000,1,1)
set.seed(1);ab2=rnorm(1000,1,1)
wilcox.test(ab2,ab)
set.seed(1);ab=rnorm(900,1,1)
set.seed(1);ab2=rnorm(900,1,1)
wilcox.test(ab2,ab)
lol2=boot::boot(rf_model,func,R=100)$t
?boot::boot
findCorrelation()
?caret::findCorrelation
findCorrelation(cor(matrix(rnorm(100),10,10)), cutoff = .9)
caret::findCorrelation(cor(matrix(rnorm(100),10,10)), cutoff = .9)
caret::findCorrelation(cor(matrix(rnorm(100),10,10)), cutoff = .1)
cor(matrix(rnorm(100),10,10))
cut(rnorm(10),breaks=c(0,0.5))
cut(runif(10),breaks=c(0,0.5))
cut(runif(10),breaks=c(0,0.5,1.5))
?caret::BoxCoxTrans
ratio <- exp(logBBB)
bc <- BoxCoxTrans(ratio)
library(caret)
ratio <- exp(logBBB)
bc <- BoxCoxTrans(ratio)
data(BloodBrain)
ratio <- exp(logBBB)
bc <- BoxCoxTrans(ratio)
predict(bc, ratio)
imported_data=import_data(file.path(system.file(package = "rDolphin"),"extdata","Parameters_MTBLS242_15spectra_5groups.csv"))
library(rDolphin)
imported_data=import_data(file.path(system.file(package = "rDolphin"),"extdata","Parameters_MTBLS242_15spectra_5groups.csv"))
debug(import_data)
imported_data=import_data(file.path(system.file(package = "rDolphin"),"extdata","Parameters_MTBLS242_15spectra_5groups.csv"))
n
n
imported_data=import_data(file.path(system.file(package = "rDolphin"),"extdata","Parameters_MTBLS242_15spectra_5groups.csv"))
metadata_path
setwd(file.path(system.file(package = "rDolphin"),"extdata")
)
imported_data=import_data("Parameters_MTBLS242_15spectra_5groups.csv")
program_parameters
dummy=read.csv(as.character(import_profile[14, 2]),stringsAsFactors = F,row.names = 1)
import_profile[14, 2]
dummy=read.csv(file.path(system.file(package = "rDolphin"),"extdata","fitting_variables.csv"),stringsAsFactors = F,row.names = 1)
dummy
dummy=tryCatch({read.csv(as.character(import_profile[14, 2]),stringsAsFactors = F,row.names = 1)
},error=function(cond) {
read.csv(file.path(system.file(package = "rDolphin"),"extdata","fitting_variables.csv"),stringsAsFactors = F,row.names = 1)
})
rm(dummy)
dummy=tryCatch({read.csv(as.character(import_profile[14, 2]),stringsAsFactors = F,row.names = 1)
},error=function(cond) {
read.csv(file.path(system.file(package = "rDolphin"),"extdata","fitting_variables.csv"),stringsAsFactors = F,row.names = 1)
})
undebug(import_data)
file.exists(as.character(import_profile[14, 2]))
debug(import_data)
imported_data=import_data("Parameters_MTBLS242_15spectra_5groups.csv")
file.exists(as.character(import_profile[14, 2]))
file.exists(import_profile[14, 2])
import_profile[14, 2]
file.exists(as.character(import_profile[14, 2]))
file.exists(file.path(system.file(package = "rDolphin"),"extdata","fitting_variables.csv"))
if (file.exists(as.character(import_profile[14, 2]))) {
prog_par_path=as.character(import_profile[14, 2])
} else if (file.exists(file.path(system.file(package = "rDolphin"),"extdata","fitting_variables.csv"))) {
prog_par_path=file.path(system.file(package = "rDolphin"),"extdata","fitting_variables.csv")
} else {
print("Error. Please provide a valid parameters csv file.")
return()
}
program_parameters=as.list(t(
read.csv(prog_par_path,
stringsAsFactors = F,
row.names = 1)))
program_parameters
program_parameters=read.csv(prog_par_path,
stringsAsFactors = F)
View(program_parameters)
program_parameters=read.csv(prog_par_path,
stringsAsFactors = F)
dummy=program_parameters[,1]
program_parameters=as.list(t(program_parameters[,2]))
names(program_parameters)=dummy
program_parameters
dummy2=lapply(program_parameters,as.numeric)
program_parameters[which(!is.na(dummy2))]=dummy2[which(!is.na(dummy2))]
program_parameters
library(rDolphin)
imported_data=import_data("Parameters_MTBLS242_15spectra_5groups.csv")
profiling_data=automatic_profiling(imported_data,imported_data$ROI_data)
?import_data
?signparpred
#'
setwd(paste(system.file(package = "rDolphin"),"extdata",sep='/'))
imported_data=import_data("Parameters_MTBLS242_15spectra_5groups.csv")
load("MTBLS242_subset_profiling_data.RData")
chemical_shift_pred=signparpred(profiling_data$final_output$chemical_shift,profiling_data$final_output$fitting_error)
install.packages("roxygen")
install.packages("roxygen2")
library(rDolphin)
?signparpred
setwd(paste(system.file(package = "rDolphin"),"extdata",sep='/'))
imported_data=import_data("Parameters_MTBLS242_15spectra_5groups.csv")
load("MTBLS242_subset_profiling_data.RData")
setwd(paste(system.file(package = "rDolphin"),"extdata",sep='/'))
imported_data=import_data("Parameters_MTBLS242_15spectra_5groups.csv")
load("MTBLS242_subset_profiling_data.RData")
library(rDolphin)
chemical_shift_pred=signparpred(profiling_data$final_output$chemical_shift,profiling_data$final_output$fitting_error)
intensity_pred=signparpred(profiling_data$final_output$intensity,profiling_data$final_output$fitting_error,imported_data$ROI_data[,4])
setwd(paste(system.file(package = "rDolphin"),"extdata",sep='/'))
imported_data=import_data("Parameters_MTBLS242_15spectra_5groups.csv")
profiling_data=automatic_profiling(imported_data,imported_data$ROI_data)
rmultinom(10, size = 12, prob = c(0.1,0.2,0.8))
pr <- c(1,3,6,10) # normalization not necessary for generation
rmultinom(10, 20, prob = pr)
# inverse transfrom sampling
num.samples <-  1000
U           <-  runif(num.samples)
X           <- -log(1-U)/2
# plot
hist(X, freq=F, xlab='X', main='Generating Exponential R.V.')
curve(dexp(x, rate=2) , 0, 3, lwd=2, xlab = "", ylab = "", add = T)
hist(U)
num.samples <- 1000
p.vec        <- c(0.1, 0.4, 0.2, 0.3)
names(p.vec) <- 1:4
samples     <- numeric(num.samples)
for(i in seq_len(num.samples) ) {
samples[i] <- discrete.inv.transform.sample(p.vec)
}
barplot(p.vec, main='True Probability Mass Function')
install.packages("KODAMA")
install.packages("C:\\Users\\dani5\\Downloads\\KODAMA_1.4.tar.gz", repos = NULL, type="source")
install.packages("RcppArmadillo")
install.packages("C:\\Users\\dani5\\Downloads\\KODAMA_1.4.tar.gz", repos = NULL, type="source")
df <- read.csv(file="C:\\Users\\dani5\\Downloads\\raw_tweets.csv",nrows=2000)
View(df)
?read.csv
df <- read.csv(file="C:\\Users\\dani5\\Downloads\\raw_tweets.csv",sep=";",nrows=2000)
library(purrr)
coef_lm <- compose(coef, summary, lm)
coef_lm(Sepal.Length ~ Species, data = iris)
map_if(iris, is.numeric, mean)
res=map_if(iris, is.numeric, mean)
res$Species
length(discard(iris, is.numeric)
)
length(res$Species)
?map_if
my_mean <- partial(mean, trim = 2, na.rm = TRUE)
map_dbl(airquality, my_mean)
possible_max <- possibly(max, otherwise = NULL)
possible_max
map(iris, possible_max)
possible_max <- possibly(max, otherwise = NA)
# Will all work
map(iris, possible_max)
map(airquality, possible_max)
map(volcano, possible_max)
map(iris, possible_max)
map(iris, possible_max)
map(airquality, possible_max)
`_eba2c079135882131db3690701bc9c97_PASTAPURCHASE_EDITED` <- read.csv("C:/Users/dani5/Downloads/_eba2c079135882131db3690701bc9c97_PASTAPURCHASE_EDITED.csv")
View(`_eba2c079135882131db3690701bc9c97_PASTAPURCHASE_EDITED`)
data <- read.csv("C:/Users/dani5/Downloads/_eba2c079135882131db3690701bc9c97_PASTAPURCHASE_EDITED.csv")
View(`_eba2c079135882131db3690701bc9c97_PASTAPURCHASE_EDITED`)
library(dplyr)
map(data,mean)
library(purrr)
map(data,mean)
map(data,sd)
View(data)
data[which.min(data$INCOME),]
data[which.max(data$INCOME),]
data%>%group_by(HHID)%>%summarize(sum)
data%>%group_by(HHID)
data%>%group_by(HHID)%>%summarize(PASTA,sum)
?summarize
lol=data%>%group_by(HHID)%>%summarize(suml=sum(PASTA))
View(lol)
lol=data%>%filter(AREA==4)%>%summarize(suml=mean(INCOME))
lol=data%>%filter(AREA==4&INCOME>20000&PASTA>30)
lol=data%>%group_by(HHID)%>%summarize_all(sum)%>%filter(AREA==4&INCOME>20000&PASTA>30)
lol=data%>%group_by(HHID)%>%summarize_all(sum)
View(lol)
lol=data%>%group_by(HHID)%>%summarize(PASTA_sum=sum(PASTA))%>%filter(AREA==4&INCOME>20000&PASTA_sum>30)
lol=data%>%group_by(HHID)%>%mutate(PASTA_sum=sum(PASTA))%>%filter(AREA==4&INCOME>20000&PASTA_sum>30)
View(lol)
lol=data%>%group_by(HHID)%>%mutate(PASTA_sum=sum(PASTA))%>%filter(AREA==4&INCOME>20000&PASTA_sum>30)%>%distinct(HHID)
lol=data%>%group_by(HHID)%>%mutate(PASTA_sum=sum(PASTA))%>%filter(AREA==2&INCOME>20000&PASTA_sum>30)%>%distinct(HHID)
data%>%cor()
lol=data%>%group_by(HHID)%>%mutate(PASTA_sum=sum(PASTA))%>%hist(PASTA_sum)
lol=data%>%group_by(HHID)%>%mutate(PASTA_sum=sum(PASTA))
lol=data%>%group_by(HHID)%>%summarize(PASTA_sum=sum(PASTA))
View(lol)
data%>%group_by(HHID)%>%summarize(PASTA_sum=sum(PASTA))%>%hist(PASTA_sum)
data%>%group_by(HHID)%>%summarize(PASTA_sum=sum(PASTA))%>%hist()
lol=data%>%group_by(HHID)%>%summarize(PASTA_sum=sum(PASTA))
summary(lol)
data%>%group_by(HHID)%>%summarize(PASTA_sum=sum(PASTA)) %>%with(hist(PASTA_sum, breaks = 50))
data%>%group_by(TIME)%>%summarize(PASTA_sum=sum(PASTA)) %>%with(plot(PASTA_sum))
data%>%group_by(TIME)%>%summarize(PASTA_sum=sum(PASTA)) %>%with(plot(TIME,PASTA_sum))
load("C:/Users/dani5/Downloads/2018_statistical_annex_all.xlsx")
library(readxl)
X2018_statistical_annex_all <- read_excel("C:/Users/dani5/Downloads/2018_statistical_annex_all.xlsx")
View(X2018_statistical_annex_all)
dataset=X2018_statistical_annex_all%>%slice(6:n())
library(dplyr)
dataset=X2018_statistical_annex_all%>%slice(6:n())
View(dataset)
colnames(X2018_statistical_annex_all)=X2018_statistical_annex_all[2,]
dataset=X2018_statistical_annex_all%>%slice(6:n())%>%purrr::keep(is.numeric)
dataset=X2018_statistical_annex_all%>%slice(6:n())
dataset=X2018_statistical_annex_all%>%slice(6:nrow(.))%>%purrr::keep(is.numeric)
dataset=X2018_statistical_annex_all[-c(1:5),]%>%purrr::keep(is.numeric)
dataset=X2018_statistical_annex_all[-c(1:5),]%>%
type.convert(.)%>%purrr::keep(is.numeric)
dataset=X2018_statistical_annex_all[-c(1:5),]%>%
type.convert(.)
View(dataset)
lapply(dataset,class)
dataset=X2018_statistical_annex_all[-c(1:5),]%>%mutate_all(as.numeric)
colnames(X2018_statistical_annex_all)=make.names(X2018_statistical_annex_all[2,])
dataset=X2018_statistical_annex_all[-c(1:5),]%>%mutate_all(as.numeric)
colnames(X2018_statistical_annex_all)=make.names(X2018_statistical_annex_all[2,],unique=T)
View(X2018_statistical_annex_all)
dataset=X2018_statistical_annex_all[-c(1:5),]%>%mutate_all(as.numeric)
View(dataset)
dataset=X2018_statistical_annex_all%>%slice(6:n())%>%mutate_all(as.numeric)%>%select_if(function(col) all(is.na(col)))
View(dataset)
dataset=X2018_statistical_annex_all%>%slice(6:n())%>%mutate_all(as.numeric)%>%select_if(function(col) !all(is.na(col)))
View(dataset)
rownames(X2018_statistical_annex_all)=X2018_statistical_annex_all[-c(1:5),2]
dataset=X2018_statistical_annex_all%>%slice(6:n())
View(dataset)
dataset$NA..3
dataset=X2018_statistical_annex_all%>%slice(6:n())%>%add_rownames(., var = "NA..3")%>%mutate_all(as.numeric)%>%select_if(function(col) !all(is.na(col)))
View(dataset)
dataset=X2018_statistical_annex_all%>%slice(6:n())
dataset=X2018_statistical_annex_all%>%slice(6:n()))%>%add_rownames(., var = "NA..3")
dataset=X2018_statistical_annex_all%>%slice(6:n())%>%add_rownames(., var = "NA..3")
dataset=X2018_statistical_annex_all%>%slice(6:n())%>%rownames_to_column(., var = "NA..3")
?tibble::rownames_to_column()
dataset=X2018_statistical_annex_all%>%slice(6:n())%>%tibble::column_to_rownames(df, var = "rowname"))%>%mutate_all(as.numeric)%>%select_if(function(col) !all(is.na(col)))
dataset=X2018_statistical_annex_all%>%slice(6:n())%>%tibble::column_to_rownames(df, var = "rowname")%>%mutate_all(as.numeric)%>%select_if(function(col) !all(is.na(col)))
dataset=X2018_statistical_annex_all%>%slice(6:n())%>%tibble::column_to_rownames(., var = "rowname")%>%mutate_all(as.numeric)%>%select_if(function(col) !all(is.na(col)))
dataset=X2018_statistical_annex_all%>%slice(6:n())%>%tibble::column_to_rownames(., var = "NA..3")%>%mutate_all(as.numeric)%>%select_if(function(col) !all(is.na(col)))
dataset=X2018_statistical_annex_all%>%slice(6:204)%>%tibble::column_to_rownames(., var = "NA..3")%>%mutate_all(as.numeric)%>%select_if(function(col) !all(is.na(col)))
View(dataset)
dataset=X2018_statistical_annex_all%>%slice(6:204)%>%tibble::column_to_rownames(., var = "NA..3")
dataset=X2018_statistical_annex_all%>%slice(6:204)%>% set_rownames(.$NA..3)
dataset=X2018_statistical_annex_all%>%slice(6:204)%>% magrittr::set_rownames(.$NA..3)
View(dataset)
dataset=X2018_statistical_annex_all%>%slice(6:204)%>% magrittr::set_rownames(.$NA..3)%>%mutate_all(as.numeric)%>%select_if(function(col) !all(is.na(col)))
View(dataset)
dataset=X2018_statistical_annex_all%>%as.data.frame()%>%slice(6:204)%>% magrittr::set_rownames(.$NA..3)%>%mutate_all(as.numeric)%>%select_if(function(col) !all(is.na(col)))
View(dataset)
dataset=X2018_statistical_annex_all%>%as.data.frame()%>%slice(6:204)%>% magrittr::set_rownames(.$NA..3)
View(dataset)
dataset=X2018_statistical_annex_all%>%as.data.frame()%>%slice(6:204)%>% magrittr::set_rownames(.$NA..3)%>%mutate_all(as.numeric)
View(dataset)
rownames(X2018_statistical_annex_all)=make.names(X2018_statistical_annex_all[,2],unique=T)
dataset=X2018_statistical_annex_all%>%as.data.frame()%>%slice(6:204)%>% mutate_all(as.numeric)%>%select_if(function(col) !all(is.na(col)))
View(dataset)
dataset=X2018_statistical_annex_all%>%as.data.frame()%>%slice(6:204)%>% mutate_all(as.numeric)%>%select_if(function(col) !all(is.na(col)))%>%select(-NA..2)%>%magrittr::set_rownames(X2018_statistical_annex_all[6:204,2])
dataset=X2018_statistical_annex_all%>%as.data.frame()%>%slice(6:204)%>% mutate_all(as.numeric)%>%select_if(function(col) !all(is.na(col)))%>%select(-NA..2)
length(X2018_statistical_annex_all[6:204,2])
X2018_statistical_annex_all[6:204,2]
X2018_statistical_annex_all <- read_excel("C:/Users/dani5/Downloads/2018_statistical_annex_all.xlsx")%>%as.data.frame()
dataset=X2018_statistical_annex_all%>%as.data.frame()%>%slice(6:204)%>% mutate_all(as.numeric)%>%select_if(function(col) !all(is.na(col)))%>%select(-NA..2)%>%magrittr::set_rownames(X2018_statistical_annex_all[6:204,2])
colnames(X2018_statistical_annex_all)=make.names(X2018_statistical_annex_all[2,],unique=T)
rownames(X2018_statistical_annex_all)=make.names(X2018_statistical_annex_all[,2],unique=T)
View(X2018_statistical_annex_all)
dataset=X2018_statistical_annex_all%>%slice(6:204)%>% mutate_all(as.numeric)%>%select_if(function(col) !all(is.na(col)))%>%select(-NA..2)
View(dataset)
dataset=X2018_statistical_annex_all%>%as.data.frame()%>%slice(6:204)%>% mutate_all(as.numeric)%>%select_if(function(col) !all(is.na(col)))%>%select(-NA..2)%>%magrittr::set_rownames(X2018_statistical_annex_all[6:204,2])
View(dataset)
View(dataset)
ab=caret::train(Human.Development.Index..HDI.~.,dataset,method="xgbTree")
dataset=X2018_statistical_annex_all%>%as.data.frame()%>%slice(6:204)%>% mutate_all(as.numeric)%>%select_if(function(col) !all(is.na(col)))%>%select(-c(NA..2,HDI.rank))%>%magrittr::set_rownames(X2018_statistical_annex_all[6:204,2])
View(dataset)
dataset=missRanger::missRanger(dataset)
View(dataset)
dataset=X2018_statistical_annex_all%>%as.data.frame()%>%slice(6:204)%>% mutate_all(as.numeric)%>%select_if(function(col) !all(is.na(col)))%>%select(-c(NA..2,HDI.rank,GNI.per.capita.rank.minus.HDI.rank))%>%magrittr::set_rownames(X2018_statistical_annex_all[6:204,2])
ab=caret::train(Human.Development.Index..HDI.~.,dataset,method="xgbTree")
dataset=X2018_statistical_annex_all%>%as.data.frame()%>%slice(6:204)%>% mutate_all(as.numeric)%>%select_if(function(col) !all(is.na(col)))%>%select(-c(NA..2,HDI.rank))%>%magrittr::set_rownames(X2018_statistical_annex_all[6:204,2])%>%missRanger::missRanger(.)
ab=caret::train(Human.Development.Index..HDI.~.,dataset,method="xgbTree")
ab
varImp(ab)
View(X2018_statistical_annex_all)
library(DALEX)
explainer <-
DALEX::explain(ab,
data=dataset)
?varaible_response
?variable_response
plot(variable_response(explainer,"Mean.years.of.schooling",type="ale")
plot(variable_response(explainer,"Mean.years.of.schooling",type="ale"))
plot(variable_response(explainer,"Gross.national.income..GNI..per.capita",type="ale"))
plot(variable_response(explainer,"Expected.years.of.schooling",type="ale"))
plot(variable_response(explainer,"Life.expectancy.at.birth",type="ale"))
plot(variable_dropout(explainer)
)
explainer <-
DALEX::explain(ab,
data=datasety=dataset$Human.Development.Index..HDI.)
explainer <-
DALEX::explain(ab,
data=dataset,y=dataset$Human.Development.Index..HDI.)
plot(variable_dropout(explainer))
plot(variable_dropout(explainer))
plot(variable_dropout(explainer))
?downSample
load("~/Projects/PhD/p_value_dist/data/allp_reduced.RData")
xgboost.model_no_country
xgboost.model
library(onehot)
one_hot_country_info=predict(onehot(p_value_final["Country"],max_levels=20),p_value_final["Country"])
i=2
set.seed(1);china <- train(pvalue ~ .,
p_value_final%>%mutate(Country=one_hot_country_info[,i]) ,
method = "xgbTree",
tuneGrid = xgb_grid,
trControl = train_control)
library(onehot)
library(caret)
library(dplyr)
library(xgboost)
library(DALEX)
library(onehot)
one_hot_country_info=predict(onehot(p_value_final["Country"],max_levels=20),p_value_final["Country"])
i=2
set.seed(1);china <- train(pvalue ~ .,
p_value_final%>%mutate(Country=one_hot_country_info[,i]) ,
method = "xgbTree",
tuneGrid = xgb_grid,
trControl = train_control)
china
set.seed(1);train_idx <- createDataPartition(
p_value_final$pvalue,
p=0.1,
list = FALSE)
set.seed(1);train_idx <- createDataPartition(
p_value_final$pvalue,
p=0.1,
list = FALSE)
set.seed(1);china <- train(pvalue ~ .,
p_value_final%>%mutate(Country=one_hot_country_info[,i])%>%slice(train_idx) ,
method = "ranger",
# tuneGrid = xgb_grid,
trControl = train_control)
set.seed(1);china <- train(pvalue ~ .,
p_value_final%>%mutate(Country=one_hot_country_info[,i])%>%slice(as.vector(train_idx)) ,
method = "ranger",
# tuneGrid = xgb_grid,
trControl = train_control)
set.seed(1);china <- train(pvalue ~ .,
p_value_final%>%mutate(Country=one_hot_country_info[,i])%>%slice(.,as.vector(train_idx)) ,
method = "ranger",
# tuneGrid = xgb_grid,
trControl = train_control)
dim(p_value_final%>%mutate(Country=one_hot_country_info[,i])%>%filter(train_idx))
dim(p_value_final%>%mutate(Country=one_hot_country_info[,i])%>%filter(train_idx %in% seq(nrow(p_value_final))))
dim(p_value_final%>%mutate(Country=one_hot_country_info[,i])%>%filter(seq(nrow(p_value_final)) %in% train_idx))
set.seed(1);china <- train(pvalue ~ .,
p_value_final%>%
mutate(Country=one_hot_country_info[,i])%>%
filter(seq(nrow(p_value_final)) %in% train_idx),
method = "ranger",
# tuneGrid = xgb_grid,
trControl = train_control)
train_control <- trainControl(method = "repeatedcv",
number = 2,
repeats=5,
seeds=as.list(1:11),
savePredictions = "final")
set.seed(1);china <- train(pvalue ~ .,
p_value_final%>%
mutate(Country=one_hot_country_info[,i])%>%
filter(seq(nrow(p_value_final)) %in% train_idx),
method = "ranger",
# tuneGrid = xgb_grid,
trControl = train_control)
train_control <- trainControl(method = "repeatedcv",
number = 2,
repeats=5,
# seeds=as.list(1:11),
savePredictions = "final")
set.seed(1);china <- train(pvalue ~ .,
p_value_final%>%
mutate(Country=one_hot_country_info[,i])%>%
filter(seq(nrow(p_value_final)) %in% train_idx),
method = "ranger",
# tuneGrid = xgb_grid,
trControl = train_control)
china
savePredictions = "final")
rf_grid <- expand.grid(
.mtry = c(6),
.splitrule = "gini"
)
set.seed(1);china <- train(pvalue ~ .,
p_value_final%>%
mutate(Country=one_hot_country_info[,i]),
method = "ranger",
tuneGrid = rf_grid,
trControl = train_control)
rf_grid <- expand.grid(
.mtry = c(6),
.splitrule = c("gini"),
.min.node.size = c(1)
)
set.seed(1);china <- train(pvalue ~ .,
p_value_final%>%
mutate(Country=one_hot_country_info[,i]),
method = "ranger",
tuneGrid = rf_grid,
trControl = train_control)
china
set.seed(1);no_country <- train(pvalue ~ .,
p_value_final%>%
select(-Country),
method = "ranger",
tuneGrid = rf_grid,
trControl = train_control)
no_country
paired_ttest_5x2_cv=function(baseline_model,comparison_model) {
phat=squared_s=rep(NA,10)
eff_size=c()
for (i in seq(1,9,2)) {
unique_folds=unique(baseline_model$pred$Resample)
fold1_model1=baseline_model$pred[baseline_model$pred$Resample==unique_folds[i],]
fold1_model2=comparison_model$pred[comparison_model$pred$Resample==unique_folds[i],]
p1=confusionMatrix(fold1_model2$pred,fold1_model2$obs)$overall[2]-
confusionMatrix(fold1_model1$pred,fold1_model1$obs)$overall[2]
fold2_model1=baseline_model$pred[baseline_model$pred$Resample==unique_folds[i+1],]
fold2_model2=comparison_model$pred[comparison_model$pred$Resample==unique_folds[i+1],]
p2=confusionMatrix(fold2_model2$pred,fold2_model2$obs)$overall[2]-
confusionMatrix(fold2_model1$pred,fold2_model1$obs)$overall[2]
phat[i]=mean(c(p1,p2))
squared_s[i]=(p1-phat[i])^2+(p2-phat[i])^2
eff_size=c(eff_size,mean(c(p1/confusionMatrix(fold1_model1$pred,fold1_model1$obs)$overall[2],
(p2/confusionMatrix(fold2_model1$pred,fold2_model1$obs)$overall[2]))))
}
phat=na.omit(phat)
squared_s=na.omit(squared_s)
mean_eff_size=mean(eff_size,na.rm=T)
fold1_model1=baseline_model$pred[baseline_model$pred$Resample==unique_folds[1],]
fold1_model2=comparison_model$pred[comparison_model$pred$Resample==unique_folds[1],]
p1=confusionMatrix(fold1_model1$pred,fold1_model1$obs)$overall[2]-
confusionMatrix(fold1_model2$pred,fold1_model2$obs)$overall[2]
t_statistic=p1/(sqrt(0.2*sum(squared_s)))
p_value=2*pt(-abs(t_statistic),df=5)
names(p_value)=NULL
#paste0("The mean effect size (5 repeats) is ",formatC(mean(eff_size), format = "e", digits = 2))
#paste0("The p-value is ",formatC(p_value, format = "e", digits = 2))
output=list(p_value=p_value,mean_eff_size=mean_eff_size)
return(output)
}
paired_ttest_5x2_cv(no_country,china)
devtools::install_github("danielcanueto/rDolphin",force=T)
devtools::install("C:/Users/dani5/Documents/GitHub/rDolphin")
